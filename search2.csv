,eid,doi,pii,pubmed_id,title,subtype,subtypeDescription,creator,afid,affilname,affiliation_city,affiliation_country,author_count,author_names,author_ids,author_afids,coverDate,coverDisplayDate,publicationName,issn,source_id,eIssn,aggregationType,volume,issueIdentifier,article_number,pageRange,description,authkeywords,citedby_count,openaccess,freetoread,freetoreadLabel,fund_acr,fund_no,fund_sponsor
0,2-s2.0-85127525305,10.1016/j.eswa.2022.117013,S0957417422004316,,Deep reinforcement learning with the confusion-matrix-based dynamic reward function for customer credit scoring,ar,Article,Wang Y.,60128181;60017244,Business School of Sichuan University;Southwest Petroleum University China,Chengdu;Chengdu,China;China,4,"Wang, Yadong;Jia, Yanlin;Tian, Yuhang;Xiao, Jin",57224115864;55793383200;57210190357;56373722900,60128181;60017244;60128181;60128181,2022-08-15,15 August 2022,Expert Systems with Applications,09574174,24201,,Journal,200,,117013,,"Customer credit scoring is a dynamic interactive process. Simply designing the static reward function for deep reinforcement learning may be difficult to guide an agent to adapt to the change of the customer credit scoring environment. To solve this problem, we propose the deep Q-network with the confusion-matrix-based dynamic reward function (DQN-CMDRF) model. Especially, the new constructed dynamic reward function can adjust the reward dynamically according to the change of confusion matrix after each deep Q-network model training, which can guide the agent to adapt to the change of environment quickly, so as to improve the customer credit scoring performance of the deep Q-network model. First, we formulate customer credit scoring as a finite Markov decision process. Second, to adjust the reward dynamically according to the customer credit scoring environment, the dynamic reward function is designed based on the confusion matrix. Finally, we introduce the confusion-matrix-based dynamic reward function into the deep Q-network model for customer credit scoring. To verify the effectiveness of the proposed model, we introduce four evaluation measures and make a series of experiments on the five customer credit scoring datasets. The experimental results show that the constructed dynamic reward function can more effectively improve customer credit scoring performance of the deep Q-network model, and the performance of the DQN-CMDRF model is significantly better than that of the other eight traditional classification models. More importantly, we find that the constructed dynamic reward function can accelerate the convergence speed and improve the stability of the deep Q-network model.",Confusion matrix | Customer credit scoring | Deep Q-network | Deep reinforcement learning | Dynamic reward function,15,0,,,NSFC,PXM2021-178216-000002,National Natural Science Foundation of China
1,2-s2.0-85124169983,,,,"International Conference on Information, Communication and Cybersecurity, ICI2C 2021",cr,Conference Review,,,,,,,,,,2022-01-01,2022,Lecture Notes in Networks and Systems,23673370,21100901469,23673389,Book Series,357 LNNS,,,,"The proceedings contain 54 papers. The special focus in this conference is on Information, Communication and Cybersecurity. The topics include: Metadata Quality in the Era of Big Data and Unstructured Content; weather Forecast Using Sliding Window Algorithm Based on Hadoop and MapReduce; semantic Web Technologies for Internet of Things Semantic Interoperability; composition of Large Modular Ontologies Based on Structure; detection and Prediction Using Similar Trajectory Measurements; Classification of Arrhythmias from ECG Using Fractal Dimensions and Wavelet Theory; benchmarking Classification Algorithms for Measuring the Performance on Maintainable Applications; application of Machine Learning Techniques for Credit Risk Management: A Survey; Applying Advanced IoT Network Topologies to Enhance Intelligent City Transportation Cost Based on a Constrained and Secured Applicative IoT CoAP Protocol; a Minimum and Maximum of Regional Information Method to Improve the Sobel Edge Detector; Applying Lightweight Elliptic Curve Cryptography ECC to Smart Energy IoT Platforms Based on the CoAP Protocol; service Selection in Cloud Computing Environment by Using Cuckoo Search; markov Decision Processes with Discounted Rewards: Improved Successive Over-Relaxation Method; speech Spectral Subtraction in Modulation Domain; COBIT 5 Concepts: Towards the Development of an Ontology Model; a Systematic Study on Tertiary Level Student Tuition Fee Waiver Management During Pandemic Using Machine Learning Approaches; towards a Model of Self-regulated e-learning and Personalization of Resources; the Preferences and Expectation of Moroccan Teachers from Learning Analytics Dashboards in a Blended Learning Environment: Empirical Study; towards a Smart City Stakeholders Classification: Case of Casablanca Smart City Project; emerging Learning Environments and Technologies Post Covid-19 Pandemic: What’s Next?.",,0,0,,,,undefined,
2,2-s2.0-85117990743,,,,Model updating after interventions paradoxically introduces bias,cp,Conference Paper,Liley J.,60163091;60111768;60022175;60022106;60021923;60012914,"Faculty of Science, Engineering and Medicine;The Alan Turing Institute;Durham University;Wellcome Trust;King's College Hospital;MRC Human Genetics Unit",Coventry;London;Durham;London;London;Edinburgh,United Kingdom;United Kingdom;United Kingdom;United Kingdom;United Kingdom;United Kingdom,6,"Liley, James;Emerson, Samuel R.;Mateen, Bilal A.;Vallejos, Catalina A.;Aslett, Louis J.M.;Vollmer, Sebastian J.",56543277400;57222573389;57192091216;57038529000;56196813200;57843571000,60111768-60012914;60022175;60111768-60021923-60022106;60111768-60012914;60111768-60022175;60111768-60163091,2021-01-01,2021,Proceedings of Machine Learning Research,,21101153015,26403498,Conference Proceeding,130,,,3916-3924,"Machine learning is increasingly being used to generate prediction models for use in a number of real-world settings, from credit risk assessment to clinical decision support. Recent discussions have highlighted potential problems in the updating of a predictive score for a binary outcome when an existing predictive score forms part of the standard workflow, driving interventions. In this setting, the existing score induces an additional causative pathway which leads to miscalibration when the original score is replaced. We propose a general causal framework to describe and address this problem, and demonstrate an equivalent formulation as a partially observed Markov decision process. We use this model to demonstrate the impact of such 'naive updating' when performed repeatedly. Namely, we show that successive predictive scores may converge to a point where they predict their own effect, or may eventually tend toward a stable oscillation between two values, and we argue that neither outcome is desirable. Furthermore, we demonstrate that even if model-fitting procedures improve, actual performance may worsen. We complement these findings with a discussion of several potential routes to overcome these issues.",,5,0,,,ATI,EP/T001569/1,Alan Turing Institute
3,2-s2.0-85060709473,10.1016/j.engappai.2019.01.010,S0952197619300107,,Reinforcement learning for pricing strategy optimization in the insurance industry,ar,Article,Krasheninnikova E.,60096819;60001741,BBVA S.A.;Universidad Carlos III de Madrid,Bilbao;Getafe,Spain;Spain,4,"Krasheninnikova, Elena;García, Javier;Maestre, Roberto;Fernández, Fernando",57205596037;57196717269;57204770846;7401589140,60096819;60001741;60096819;60001741,2019-04-01,April 2019,Engineering Applications of Artificial Intelligence,09521976,24182,,Journal,80,,,8-19,"Pricing is a fundamental problem in the banking sector, and is closely related to a number of financial products such as credit scoring or insurance. In the insurance industry an important question arises, namely: how can insurance renewal prices be adjusted? Such an adjustment has two conflicting objectives. On the one hand, insurers are forced to retain existing customers, while on the other hand insurers are also forced to increase revenue. Intuitively, one might assume that revenue increases by offering high renewal prices, however this might also cause many customers to terminate their contracts. Contrarily, low renewal prices help retain most existing customers, but could negatively affect revenue. Therefore, adjusting renewal prices is a non-trivial problem for the insurance industry. In this paper, we propose a novel modelization of the renewal price adjustment problem as a sequential decision problem and, consequently, as a Markov decision process (MDP). In particular, this study analyzes two different strategies to carry out this adjustment. The first is about maximizing revenue analyzing the effect of this maximization on customer retention, while the second is about maximizing revenue subject to the client retention level not falling below a given threshold. The former case is related to MDPs with a single criterion to be optimized. The latter case is related to Constrained MDPs (CMDPs) with two criteria, where the first one is related to optimization, while the second is subject to a constraint. This paper also contributes with the resolution of these models by means of a model-free Reinforcement Learning algorithm. Results have been reported using real data from the insurance division of BBVA, one of the largest Spanish companies in the banking sector.",Pricing strategy optimization | Reinforcement learning,26,0,repositoryam,Green,MINECO,2016-T2/TIC-1712,Comunidad de Madrid
4,2-s2.0-71049130207,10.1109/BIFE.2009.174,,,Referral limit policy for the credit authorization process,cp,Conference Paper,Kin K.L.,60013983,City University of Hong Kong,Hong Kong,Hong Kong,2,"Kin, Keung Lai;Bing, Lin",55433716400;57535547000,60013983;60013983,2009-11-16,2009,"2009 International Conference on Business Intelligence and Financial Engineering, BIFE 2009",,19400158356,,Conference Proceeding,,,5208750,754-757,This paper considers the credit authorization problem in credit card companies' authorization systems. Customers are classified into several risk segments according to the type of services requested and the associated credit risk of customers. Card companies need to balance the risk exposure and the quality of customer service in the decision of referral/no referral. We formulate this problem as a Markov Decision Process (MDP) and characterize the optimal policy as referral limit control for each risk segment. A numerical example is provided to verify our results. © 2009 IEEE.,Credit card | Markov decision process | Referral limit | Risk segment,0,0,,,,undefined,
5,2-s2.0-33745003656,10.1016/j.ejor.2005.06.058,S0377221705006880,,Using adaptive learning in credit scoring to estimate take-up probability distribution,ar,Article,Seow H.,60025225,University of Southampton,Southampton,United Kingdom,2,"Seow, Hsin Vonn;Thomas, Lyn C.",14009431700;7403527520,60025225;60025225,2006-09-16,16 September 2006,European Journal of Operational Research,03772217,22489,,Journal,173,3,,880-892,"Credit scoring is used by lenders to minimise the chance of taking an unprofitable account with the overall objective of maximising profit. Profit is generated when a good customer accepts an offer from the organisation. So it is also necessary to get the customers to accept the offer. A lender can ""learn"" about the customers' preferences by looking at which type of product different types of customers accepted and hence has to decide what offer to make. In this model of the acceptance problem, we model the lenders decision problem on which offer to make as a Markov Decision Process under uncertainty. The aim of this paper is to develop a model of adaptive dynamic programming where Bayesian updating methods are employed to better estimate a take-up probability distribution. The significance of Bayesian updating in this model is that it allows previous responses to be included in the decision process. This means one uses learning of the previous responses to aid in selecting offers best to be offered to prospective customers that ensure take-up. © 2005 Elsevier B.V. All rights reserved.",Bayesian updating | Credit scoring | Dynamic programming | Take-up probability,11,0,,,,undefined,
